// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"bytes"
	"encoding/json"
	"errors"
	"fmt"
)

// DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle - Name of the credentials
type DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle string

const (
	DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitleIamUser DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle = "IAM User"
)

func (e DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle) ToPointer() *DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle {
	return &e
}

func (e *DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "IAM User":
		*e = DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle: %v", v)
	}
}

// DestinationAwsDatalakeUpdateAuthenticationModeIAMUser - Choose How to Authenticate to AWS.
type DestinationAwsDatalakeUpdateAuthenticationModeIAMUser struct {
	// AWS User Access Key Id
	AwsAccessKeyID string `json:"aws_access_key_id"`
	// Secret Access Key
	AwsSecretAccessKey string `json:"aws_secret_access_key"`
	// Name of the credentials
	CredentialsTitle DestinationAwsDatalakeUpdateAuthenticationModeIAMUserCredentialsTitle `json:"credentials_title"`
}

// DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle - Name of the credentials
type DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle string

const (
	DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitleIamRole DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle = "IAM Role"
)

func (e DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle) ToPointer() *DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle {
	return &e
}

func (e *DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "IAM Role":
		*e = DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle: %v", v)
	}
}

// DestinationAwsDatalakeUpdateAuthenticationModeIAMRole - Choose How to Authenticate to AWS.
type DestinationAwsDatalakeUpdateAuthenticationModeIAMRole struct {
	// Name of the credentials
	CredentialsTitle DestinationAwsDatalakeUpdateAuthenticationModeIAMRoleCredentialsTitle `json:"credentials_title"`
	// Will assume this role to write data to s3
	RoleArn string `json:"role_arn"`
}

type DestinationAwsDatalakeUpdateAuthenticationModeType string

const (
	DestinationAwsDatalakeUpdateAuthenticationModeTypeDestinationAwsDatalakeUpdateAuthenticationModeIAMRole DestinationAwsDatalakeUpdateAuthenticationModeType = "destination-aws-datalake-update_Authentication mode_IAM Role"
	DestinationAwsDatalakeUpdateAuthenticationModeTypeDestinationAwsDatalakeUpdateAuthenticationModeIAMUser DestinationAwsDatalakeUpdateAuthenticationModeType = "destination-aws-datalake-update_Authentication mode_IAM User"
)

type DestinationAwsDatalakeUpdateAuthenticationMode struct {
	DestinationAwsDatalakeUpdateAuthenticationModeIAMRole *DestinationAwsDatalakeUpdateAuthenticationModeIAMRole
	DestinationAwsDatalakeUpdateAuthenticationModeIAMUser *DestinationAwsDatalakeUpdateAuthenticationModeIAMUser

	Type DestinationAwsDatalakeUpdateAuthenticationModeType
}

func CreateDestinationAwsDatalakeUpdateAuthenticationModeDestinationAwsDatalakeUpdateAuthenticationModeIAMRole(destinationAwsDatalakeUpdateAuthenticationModeIAMRole DestinationAwsDatalakeUpdateAuthenticationModeIAMRole) DestinationAwsDatalakeUpdateAuthenticationMode {
	typ := DestinationAwsDatalakeUpdateAuthenticationModeTypeDestinationAwsDatalakeUpdateAuthenticationModeIAMRole

	return DestinationAwsDatalakeUpdateAuthenticationMode{
		DestinationAwsDatalakeUpdateAuthenticationModeIAMRole: &destinationAwsDatalakeUpdateAuthenticationModeIAMRole,
		Type: typ,
	}
}

func CreateDestinationAwsDatalakeUpdateAuthenticationModeDestinationAwsDatalakeUpdateAuthenticationModeIAMUser(destinationAwsDatalakeUpdateAuthenticationModeIAMUser DestinationAwsDatalakeUpdateAuthenticationModeIAMUser) DestinationAwsDatalakeUpdateAuthenticationMode {
	typ := DestinationAwsDatalakeUpdateAuthenticationModeTypeDestinationAwsDatalakeUpdateAuthenticationModeIAMUser

	return DestinationAwsDatalakeUpdateAuthenticationMode{
		DestinationAwsDatalakeUpdateAuthenticationModeIAMUser: &destinationAwsDatalakeUpdateAuthenticationModeIAMUser,
		Type: typ,
	}
}

func (u *DestinationAwsDatalakeUpdateAuthenticationMode) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	destinationAwsDatalakeUpdateAuthenticationModeIAMRole := new(DestinationAwsDatalakeUpdateAuthenticationModeIAMRole)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationAwsDatalakeUpdateAuthenticationModeIAMRole); err == nil {
		u.DestinationAwsDatalakeUpdateAuthenticationModeIAMRole = destinationAwsDatalakeUpdateAuthenticationModeIAMRole
		u.Type = DestinationAwsDatalakeUpdateAuthenticationModeTypeDestinationAwsDatalakeUpdateAuthenticationModeIAMRole
		return nil
	}

	destinationAwsDatalakeUpdateAuthenticationModeIAMUser := new(DestinationAwsDatalakeUpdateAuthenticationModeIAMUser)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationAwsDatalakeUpdateAuthenticationModeIAMUser); err == nil {
		u.DestinationAwsDatalakeUpdateAuthenticationModeIAMUser = destinationAwsDatalakeUpdateAuthenticationModeIAMUser
		u.Type = DestinationAwsDatalakeUpdateAuthenticationModeTypeDestinationAwsDatalakeUpdateAuthenticationModeIAMUser
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationAwsDatalakeUpdateAuthenticationMode) MarshalJSON() ([]byte, error) {
	if u.DestinationAwsDatalakeUpdateAuthenticationModeIAMRole != nil {
		return json.Marshal(u.DestinationAwsDatalakeUpdateAuthenticationModeIAMRole)
	}

	if u.DestinationAwsDatalakeUpdateAuthenticationModeIAMUser != nil {
		return json.Marshal(u.DestinationAwsDatalakeUpdateAuthenticationModeIAMUser)
	}

	return nil, nil
}

// DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional - The compression algorithm used to compress data.
type DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional string

const (
	DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptionalUncompressed DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional = "UNCOMPRESSED"
	DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptionalSnappy       DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional = "SNAPPY"
	DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptionalGzip         DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional = "GZIP"
	DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptionalZstd         DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional = "ZSTD"
)

func (e DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional) ToPointer() *DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional {
	return &e
}

func (e *DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "SNAPPY":
		fallthrough
	case "GZIP":
		fallthrough
	case "ZSTD":
		*e = DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional: %v", v)
	}
}

type DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard string

const (
	DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcardParquet DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard = "Parquet"
)

func (e DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard) ToPointer() *DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard {
	return &e
}

func (e *DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "Parquet":
		*e = DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard: %v", v)
	}
}

// DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage - Format of the data output.
type DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage struct {
	// The compression algorithm used to compress data.
	CompressionCodec *DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageCompressionCodecOptional `json:"compression_codec,omitempty"`
	FormatType       DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorageFormatTypeWildcard        `json:"format_type"`
}

// DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional - The compression algorithm used to compress data.
type DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional string

const (
	DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptionalUncompressed DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional = "UNCOMPRESSED"
	DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptionalGzip         DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional = "GZIP"
)

func (e DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional) ToPointer() *DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional {
	return &e
}

func (e *DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "UNCOMPRESSED":
		fallthrough
	case "GZIP":
		*e = DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional: %v", v)
	}
}

type DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard string

const (
	DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcardJsonl DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard = "JSONL"
)

func (e DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard) ToPointer() *DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard {
	return &e
}

func (e *DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JSONL":
		*e = DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard: %v", v)
	}
}

// DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON - Format of the data output.
type DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON struct {
	// The compression algorithm used to compress data.
	CompressionCodec *DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONCompressionCodecOptional `json:"compression_codec,omitempty"`
	FormatType       DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSONFormatTypeWildcard        `json:"format_type"`
}

type DestinationAwsDatalakeUpdateOutputFormatWildcardType string

const (
	DestinationAwsDatalakeUpdateOutputFormatWildcardTypeDestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON DestinationAwsDatalakeUpdateOutputFormatWildcardType = "destination-aws-datalake-update_Output Format *_JSON Lines: Newline-delimited JSON"
	DestinationAwsDatalakeUpdateOutputFormatWildcardTypeDestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage        DestinationAwsDatalakeUpdateOutputFormatWildcardType = "destination-aws-datalake-update_Output Format *_Parquet: Columnar Storage"
)

type DestinationAwsDatalakeUpdateOutputFormatWildcard struct {
	DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON *DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON
	DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage        *DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage

	Type DestinationAwsDatalakeUpdateOutputFormatWildcardType
}

func CreateDestinationAwsDatalakeUpdateOutputFormatWildcardDestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON(destinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON) DestinationAwsDatalakeUpdateOutputFormatWildcard {
	typ := DestinationAwsDatalakeUpdateOutputFormatWildcardTypeDestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON

	return DestinationAwsDatalakeUpdateOutputFormatWildcard{
		DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON: &destinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON,
		Type: typ,
	}
}

func CreateDestinationAwsDatalakeUpdateOutputFormatWildcardDestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage(destinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage) DestinationAwsDatalakeUpdateOutputFormatWildcard {
	typ := DestinationAwsDatalakeUpdateOutputFormatWildcardTypeDestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage

	return DestinationAwsDatalakeUpdateOutputFormatWildcard{
		DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage: &destinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage,
		Type: typ,
	}
}

func (u *DestinationAwsDatalakeUpdateOutputFormatWildcard) UnmarshalJSON(data []byte) error {
	var d *json.Decoder

	destinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON := new(DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON); err == nil {
		u.DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON = destinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON
		u.Type = DestinationAwsDatalakeUpdateOutputFormatWildcardTypeDestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON
		return nil
	}

	destinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage := new(DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage)
	d = json.NewDecoder(bytes.NewReader(data))
	d.DisallowUnknownFields()
	if err := d.Decode(&destinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage); err == nil {
		u.DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage = destinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage
		u.Type = DestinationAwsDatalakeUpdateOutputFormatWildcardTypeDestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage
		return nil
	}

	return errors.New("could not unmarshal into supported union types")
}

func (u DestinationAwsDatalakeUpdateOutputFormatWildcard) MarshalJSON() ([]byte, error) {
	if u.DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON != nil {
		return json.Marshal(u.DestinationAwsDatalakeUpdateOutputFormatWildcardJSONLinesNewlineDelimitedJSON)
	}

	if u.DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage != nil {
		return json.Marshal(u.DestinationAwsDatalakeUpdateOutputFormatWildcardParquetColumnarStorage)
	}

	return nil, nil
}

// DestinationAwsDatalakeUpdateChooseHowToPartitionData - Partition data by cursor fields when a cursor field is a date
type DestinationAwsDatalakeUpdateChooseHowToPartitionData string

const (
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataNoPartitioning DestinationAwsDatalakeUpdateChooseHowToPartitionData = "NO PARTITIONING"
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataDate           DestinationAwsDatalakeUpdateChooseHowToPartitionData = "DATE"
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataYear           DestinationAwsDatalakeUpdateChooseHowToPartitionData = "YEAR"
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataMonth          DestinationAwsDatalakeUpdateChooseHowToPartitionData = "MONTH"
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataDay            DestinationAwsDatalakeUpdateChooseHowToPartitionData = "DAY"
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataYearMonth      DestinationAwsDatalakeUpdateChooseHowToPartitionData = "YEAR/MONTH"
	DestinationAwsDatalakeUpdateChooseHowToPartitionDataYearMonthDay   DestinationAwsDatalakeUpdateChooseHowToPartitionData = "YEAR/MONTH/DAY"
)

func (e DestinationAwsDatalakeUpdateChooseHowToPartitionData) ToPointer() *DestinationAwsDatalakeUpdateChooseHowToPartitionData {
	return &e
}

func (e *DestinationAwsDatalakeUpdateChooseHowToPartitionData) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "NO PARTITIONING":
		fallthrough
	case "DATE":
		fallthrough
	case "YEAR":
		fallthrough
	case "MONTH":
		fallthrough
	case "DAY":
		fallthrough
	case "YEAR/MONTH":
		fallthrough
	case "YEAR/MONTH/DAY":
		*e = DestinationAwsDatalakeUpdateChooseHowToPartitionData(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateChooseHowToPartitionData: %v", v)
	}
}

// DestinationAwsDatalakeUpdateS3BucketRegion - The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes.
type DestinationAwsDatalakeUpdateS3BucketRegion string

const (
	DestinationAwsDatalakeUpdateS3BucketRegionUnknown      DestinationAwsDatalakeUpdateS3BucketRegion = ""
	DestinationAwsDatalakeUpdateS3BucketRegionUsEast1      DestinationAwsDatalakeUpdateS3BucketRegion = "us-east-1"
	DestinationAwsDatalakeUpdateS3BucketRegionUsEast2      DestinationAwsDatalakeUpdateS3BucketRegion = "us-east-2"
	DestinationAwsDatalakeUpdateS3BucketRegionUsWest1      DestinationAwsDatalakeUpdateS3BucketRegion = "us-west-1"
	DestinationAwsDatalakeUpdateS3BucketRegionUsWest2      DestinationAwsDatalakeUpdateS3BucketRegion = "us-west-2"
	DestinationAwsDatalakeUpdateS3BucketRegionAfSouth1     DestinationAwsDatalakeUpdateS3BucketRegion = "af-south-1"
	DestinationAwsDatalakeUpdateS3BucketRegionApEast1      DestinationAwsDatalakeUpdateS3BucketRegion = "ap-east-1"
	DestinationAwsDatalakeUpdateS3BucketRegionApSouth1     DestinationAwsDatalakeUpdateS3BucketRegion = "ap-south-1"
	DestinationAwsDatalakeUpdateS3BucketRegionApNortheast1 DestinationAwsDatalakeUpdateS3BucketRegion = "ap-northeast-1"
	DestinationAwsDatalakeUpdateS3BucketRegionApNortheast2 DestinationAwsDatalakeUpdateS3BucketRegion = "ap-northeast-2"
	DestinationAwsDatalakeUpdateS3BucketRegionApNortheast3 DestinationAwsDatalakeUpdateS3BucketRegion = "ap-northeast-3"
	DestinationAwsDatalakeUpdateS3BucketRegionApSoutheast1 DestinationAwsDatalakeUpdateS3BucketRegion = "ap-southeast-1"
	DestinationAwsDatalakeUpdateS3BucketRegionApSoutheast2 DestinationAwsDatalakeUpdateS3BucketRegion = "ap-southeast-2"
	DestinationAwsDatalakeUpdateS3BucketRegionCaCentral1   DestinationAwsDatalakeUpdateS3BucketRegion = "ca-central-1"
	DestinationAwsDatalakeUpdateS3BucketRegionCnNorth1     DestinationAwsDatalakeUpdateS3BucketRegion = "cn-north-1"
	DestinationAwsDatalakeUpdateS3BucketRegionCnNorthwest1 DestinationAwsDatalakeUpdateS3BucketRegion = "cn-northwest-1"
	DestinationAwsDatalakeUpdateS3BucketRegionEuCentral1   DestinationAwsDatalakeUpdateS3BucketRegion = "eu-central-1"
	DestinationAwsDatalakeUpdateS3BucketRegionEuNorth1     DestinationAwsDatalakeUpdateS3BucketRegion = "eu-north-1"
	DestinationAwsDatalakeUpdateS3BucketRegionEuSouth1     DestinationAwsDatalakeUpdateS3BucketRegion = "eu-south-1"
	DestinationAwsDatalakeUpdateS3BucketRegionEuWest1      DestinationAwsDatalakeUpdateS3BucketRegion = "eu-west-1"
	DestinationAwsDatalakeUpdateS3BucketRegionEuWest2      DestinationAwsDatalakeUpdateS3BucketRegion = "eu-west-2"
	DestinationAwsDatalakeUpdateS3BucketRegionEuWest3      DestinationAwsDatalakeUpdateS3BucketRegion = "eu-west-3"
	DestinationAwsDatalakeUpdateS3BucketRegionSaEast1      DestinationAwsDatalakeUpdateS3BucketRegion = "sa-east-1"
	DestinationAwsDatalakeUpdateS3BucketRegionMeSouth1     DestinationAwsDatalakeUpdateS3BucketRegion = "me-south-1"
	DestinationAwsDatalakeUpdateS3BucketRegionUsGovEast1   DestinationAwsDatalakeUpdateS3BucketRegion = "us-gov-east-1"
	DestinationAwsDatalakeUpdateS3BucketRegionUsGovWest1   DestinationAwsDatalakeUpdateS3BucketRegion = "us-gov-west-1"
)

func (e DestinationAwsDatalakeUpdateS3BucketRegion) ToPointer() *DestinationAwsDatalakeUpdateS3BucketRegion {
	return &e
}

func (e *DestinationAwsDatalakeUpdateS3BucketRegion) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "":
		fallthrough
	case "us-east-1":
		fallthrough
	case "us-east-2":
		fallthrough
	case "us-west-1":
		fallthrough
	case "us-west-2":
		fallthrough
	case "af-south-1":
		fallthrough
	case "ap-east-1":
		fallthrough
	case "ap-south-1":
		fallthrough
	case "ap-northeast-1":
		fallthrough
	case "ap-northeast-2":
		fallthrough
	case "ap-northeast-3":
		fallthrough
	case "ap-southeast-1":
		fallthrough
	case "ap-southeast-2":
		fallthrough
	case "ca-central-1":
		fallthrough
	case "cn-north-1":
		fallthrough
	case "cn-northwest-1":
		fallthrough
	case "eu-central-1":
		fallthrough
	case "eu-north-1":
		fallthrough
	case "eu-south-1":
		fallthrough
	case "eu-west-1":
		fallthrough
	case "eu-west-2":
		fallthrough
	case "eu-west-3":
		fallthrough
	case "sa-east-1":
		fallthrough
	case "me-south-1":
		fallthrough
	case "us-gov-east-1":
		fallthrough
	case "us-gov-west-1":
		*e = DestinationAwsDatalakeUpdateS3BucketRegion(v)
		return nil
	default:
		return fmt.Errorf("invalid value for DestinationAwsDatalakeUpdateS3BucketRegion: %v", v)
	}
}

type DestinationAwsDatalakeUpdate struct {
	// target aws account id
	AwsAccountID *string `json:"aws_account_id,omitempty"`
	// The name of the S3 bucket. Read more <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html">here</a>.
	BucketName string `json:"bucket_name"`
	// S3 prefix
	BucketPrefix *string `json:"bucket_prefix,omitempty"`
	// Choose How to Authenticate to AWS.
	Credentials DestinationAwsDatalakeUpdateAuthenticationMode `json:"credentials"`
	// Format of the data output.
	Format *DestinationAwsDatalakeUpdateOutputFormatWildcard `json:"format,omitempty"`
	// Cast float/double as decimal(38,18). This can help achieve higher accuracy and represent numbers correctly as received from the source.
	GlueCatalogFloatAsDecimal *bool `json:"glue_catalog_float_as_decimal,omitempty"`
	// Add a default tag key to databases created by this destination
	LakeformationDatabaseDefaultTagKey *string `json:"lakeformation_database_default_tag_key,omitempty"`
	// Add default values for the `Tag Key` to databases created by this destination. Comma separate for multiple values.
	LakeformationDatabaseDefaultTagValues *string `json:"lakeformation_database_default_tag_values,omitempty"`
	// The default database this destination will use to create tables in per stream. Can be changed per connection by customizing the namespace.
	LakeformationDatabaseName string `json:"lakeformation_database_name"`
	// Whether to create tables as LF governed tables.
	LakeformationGovernedTables *bool `json:"lakeformation_governed_tables,omitempty"`
	// Partition data by cursor fields when a cursor field is a date
	Partitioning *DestinationAwsDatalakeUpdateChooseHowToPartitionData `json:"partitioning,omitempty"`
	// The region of the S3 bucket. See <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-available-regions">here</a> for all region codes.
	Region DestinationAwsDatalakeUpdateS3BucketRegion `json:"region"`
}
